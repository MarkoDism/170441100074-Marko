<!doctype html><html lang="en" class="no-js"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta http-equiv="x-ua-compatible" content="ie=edge"><meta name="description" content="Tugas Data Mining B"><link rel="canonical" href="https://github.com/MarkoDism/170441100074-Marko/"><meta name="lang:clipboard.copy" content="Copy to clipboard"><meta name="lang:clipboard.copied" content="Copied to clipboard"><meta name="lang:search.language" content="en"><meta name="lang:search.pipeline.stopwords" content="True"><meta name="lang:search.pipeline.trimmer" content="True"><meta name="lang:search.result.none" content="No matching documents"><meta name="lang:search.result.one" content="1 matching document"><meta name="lang:search.result.other" content="# matching documents"><meta name="lang:search.tokenizer" content="[\s\-]+"><link rel="shortcut icon" href="assets/images/favicon.png"><meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.3.0"><title>170441100074-Marko</title><link rel="stylesheet" href="assets/stylesheets/application.4031d38b.css"><link rel="stylesheet" href="assets/stylesheets/application-palette.224b79ff.css"><meta name="theme-color" content="#3f51b5"><script src="assets/javascripts/modernizr.74668098.js"></script><link href="https://fonts.gstatic.com" rel="preconnect" crossorigin><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=swap"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel="stylesheet" href="assets/fonts/material-icons.css"><script>window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })</script><script async src="https://www.google-analytics.com/analytics.js"></script></head><body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo"><svg class="md-svg"><defs><svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg></defs></svg> <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off"> <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off"> <label class="md-overlay" data-md-component="overlay" for="__drawer"></label><a href="#decision-tree-pohon-keputusan" tabindex="1" class="md-skip">Skip to content </a><header class="md-header" data-md-component="header"><nav class="md-header-nav md-grid"><div class="md-flex"><div class="md-flex__cell md-flex__cell--shrink"><a href="https://github.com/MarkoDism/170441100074-Marko" title="170441100074-Marko" class="md-header-nav__button md-logo"><i class="md-icon"></i></a></div><div class="md-flex__cell md-flex__cell--shrink"><label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label></div><div class="md-flex__cell md-flex__cell--stretch"><div class="md-flex__ellipsis md-header-nav__title" data-md-component="title"><span class="md-header-nav__topic">170441100074-Marko</span><span class="md-header-nav__topic">Decision Tree</span></div></div><div class="md-flex__cell md-flex__cell--shrink"><label class="md-icon md-icon--search md-header-nav__button" for="__search"></label><div class="md-search" data-md-component="search" role="dialog"><label class="md-search__overlay" for="__search"></label><div class="md-search__inner" role="search"><form class="md-search__form" name="search"><input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active"> <label class="md-icon md-search__icon" for="__search"></label> <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">&#xE5CD;</button></form><div class="md-search__output"><div class="md-search__scrollwrap" data-md-scrollfix><div class="md-search-result" data-md-component="result"><div class="md-search-result__meta">Type to start searching</div><ol class="md-search-result__list"></ol></div></div></div></div></div></div><div class="md-flex__cell md-flex__cell--shrink"><div class="md-header-nav__source"><a href="https://github.com/squidfunk/mkdocs-material" title="Go to repository" class="md-source" data-md-source="github"><div class="md-source__icon"><svg viewBox="0 0 24 24" width="24" height="24"><use xlink:href="#__github" width="24" height="24"></use></svg></div><div class="md-source__repository">squidfunk/mkdocs-material</div></a></div></div></div></nav></header><div class="md-container"><nav class="md-tabs" data-md-component="tabs"><div class="md-tabs__inner md-grid"><ul class="md-tabs__list"><li class="md-tabs__item"><a href="." title="Decision Tree" class="md-tabs__link md-tabs__link--active">Decision Tree</a></li></ul></div></nav><main class="md-main"><div class="md-main__inner md-grid" data-md-component="container"><div class="md-sidebar md-sidebar--primary" data-md-component="navigation"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav class="md-nav md-nav--primary" data-md-level="0"><label class="md-nav__title md-nav__title--site" for="__drawer"><a href="https://github.com/MarkoDism/170441100074-Marko" title="170441100074-Marko" class="md-nav__button md-logo"><i class="md-icon"></i></a>170441100074-Marko</label><div class="md-nav__source"><a href="https://github.com/squidfunk/mkdocs-material" title="Go to repository" class="md-source" data-md-source="github"><div class="md-source__icon"><svg viewBox="0 0 24 24" width="24" height="24"><use xlink:href="#__github" width="24" height="24"></use></svg></div><div class="md-source__repository">squidfunk/mkdocs-material</div></a></div><ul class="md-nav__list" data-md-scrollfix><li class="md-nav__item md-nav__item--active"><input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc"><label class="md-nav__link md-nav__link--active" for="__toc">Decision Tree</label><a href="." title="Decision Tree" class="md-nav__link md-nav__link--active">Decision Tree</a><nav class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc">Table of contents</label><ul class="md-nav__list" data-md-scrollfix><li class="md-nav__item"><a href="#pengertian" title="Pengertian" class="md-nav__link">Pengertian</a></li><li class="md-nav__item"><a href="#kelebihan-dan-kekurangan-decision-tree" title="Kelebihan dan Kekurangan Decision Tree" class="md-nav__link">Kelebihan dan Kekurangan Decision Tree</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a href="#kelebihan" title="Kelebihan:" class="md-nav__link">Kelebihan:</a></li><li class="md-nav__item"><a href="#kekurangan" title="Kekurangan:" class="md-nav__link">Kekurangan:</a></li><li class="md-nav__item"><a href="#algoritma-decision-tree-classification" title="Algoritma Decision Tree Classification¶" class="md-nav__link">Algoritma Decision Tree Classification¶</a></li></ul></nav></li><li class="md-nav__item"><a href="#implementasi-dalam-python" title="Implementasi dalam Python" class="md-nav__link">Implementasi dalam Python</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a href="#identifikasi-target-variabel" title="Identifikasi target variabel" class="md-nav__link">Identifikasi target variabel</a></li><li class="md-nav__item"><a href="#identifikasi-variabel-prediktor-dan-encode-variabel-string-apa-pun-ke-kode-integer-yang-setara" title="Identifikasi variabel prediktor dan encode variabel string apa pun ke kode integer yang setara" class="md-nav__link">Identifikasi variabel prediktor dan encode variabel string apa pun ke kode integer yang setara</a></li><li class="md-nav__item"><a href="#pilih-fitur-prediktsi-dan-variabel-target" title="Pilih fitur prediktsi dan variabel target" class="md-nav__link">Pilih fitur prediktsi dan variabel target</a></li><li class="md-nav__item"><a href="#train-test-split" title="Train test split:" class="md-nav__link">Train test split:</a></li><li class="md-nav__item"><a href="#trainingmodel-fitting" title="Training/model fitting" class="md-nav__link">Training/model fitting</a></li><li class="md-nav__item"><a href="#studi-parameter-model" title="Studi parameter model:" class="md-nav__link">Studi parameter model:</a></li><li class="md-nav__item"><a href="#visualization-of-the-decision-graph" title="Visualization of the decision graph:" class="md-nav__link">Visualization of the decision graph:</a></li><li class="md-nav__item"><a href="#refrensi" title="Refrensi" class="md-nav__link">Refrensi</a></li></ul></nav></li></ul></nav></li></ul></nav></div></div></div><div class="md-sidebar md-sidebar--secondary" data-md-component="toc"><div class="md-sidebar__scrollwrap"><div class="md-sidebar__inner"><nav class="md-nav md-nav--secondary"><label class="md-nav__title" for="__toc">Table of contents</label><ul class="md-nav__list" data-md-scrollfix><li class="md-nav__item"><a href="#pengertian" title="Pengertian" class="md-nav__link">Pengertian</a></li><li class="md-nav__item"><a href="#kelebihan-dan-kekurangan-decision-tree" title="Kelebihan dan Kekurangan Decision Tree" class="md-nav__link">Kelebihan dan Kekurangan Decision Tree</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a href="#kelebihan" title="Kelebihan:" class="md-nav__link">Kelebihan:</a></li><li class="md-nav__item"><a href="#kekurangan" title="Kekurangan:" class="md-nav__link">Kekurangan:</a></li><li class="md-nav__item"><a href="#algoritma-decision-tree-classification" title="Algoritma Decision Tree Classification¶" class="md-nav__link">Algoritma Decision Tree Classification¶</a></li></ul></nav></li><li class="md-nav__item"><a href="#implementasi-dalam-python" title="Implementasi dalam Python" class="md-nav__link">Implementasi dalam Python</a><nav class="md-nav"><ul class="md-nav__list"><li class="md-nav__item"><a href="#identifikasi-target-variabel" title="Identifikasi target variabel" class="md-nav__link">Identifikasi target variabel</a></li><li class="md-nav__item"><a href="#identifikasi-variabel-prediktor-dan-encode-variabel-string-apa-pun-ke-kode-integer-yang-setara" title="Identifikasi variabel prediktor dan encode variabel string apa pun ke kode integer yang setara" class="md-nav__link">Identifikasi variabel prediktor dan encode variabel string apa pun ke kode integer yang setara</a></li><li class="md-nav__item"><a href="#pilih-fitur-prediktsi-dan-variabel-target" title="Pilih fitur prediktsi dan variabel target" class="md-nav__link">Pilih fitur prediktsi dan variabel target</a></li><li class="md-nav__item"><a href="#train-test-split" title="Train test split:" class="md-nav__link">Train test split:</a></li><li class="md-nav__item"><a href="#trainingmodel-fitting" title="Training/model fitting" class="md-nav__link">Training/model fitting</a></li><li class="md-nav__item"><a href="#studi-parameter-model" title="Studi parameter model:" class="md-nav__link">Studi parameter model:</a></li><li class="md-nav__item"><a href="#visualization-of-the-decision-graph" title="Visualization of the decision graph:" class="md-nav__link">Visualization of the decision graph:</a></li><li class="md-nav__item"><a href="#refrensi" title="Refrensi" class="md-nav__link">Refrensi</a></li></ul></nav></li></ul></nav></div></div></div><div class="md-content"><article class="md-content__inner md-typeset"><h1 id="decision-tree-pohon-keputusan"><strong>Decision Tree</strong> (Pohon Keputusan)<a class="headerlink" href="#decision-tree-pohon-keputusan" title="Permanent link">&para;</a></h1>
<p><img alt="" src="assets/images/1.jpg" /></p>
<h2 id="pengertian">Pengertian<a class="headerlink" href="#pengertian" title="Permanent link">&para;</a></h2>
<p>Decision tree atau pohon keputusan  adalah alat pendukung keputusan yang menggunakan model keputusan yang  berbentuk seperti pohon. Decision tree memetakan berbagai alternatif  yang mungkin untuk mengatasi suatu masalah, dan terdapat juga  faktor-faktor kemungkinan yang dapat mempengaruhi alternatif tersebut  beserta estimasi akhirnya jika memilih alternatif yang ada. Decision  tree merupakan salah satu metode yang bisa digunaan untuk menampilkan  algoritma dimana hanya berisi pernyataan kontrol bersyarat.</p>
<p>Penggunaan Decision tree ini umunya  dalam riset operasi, khususnya dalam analisis keputusan. Tujuan dalam  menggunakan Decision tree untuk membantu mengidentifikasi strategi yang  paling mungkin untuk mencapai tujuan dan merupakan alat yang populer  dalam machine learning.</p>
<p>Decision tree merupakan struktur seperti  bagan alur dimana setiap simpul internal mewakili kemungkinan yang ada  pada atribut, setiap cabang mewakili hasil dari kemungkinan tersebut,  dan setiap simpul daun mewakili label kelas (keputusan diambil setelah  menghitung semua atribut). Jalur dari root ke daun mewakili aturan  klasifikasi.</p>
<p>Dalam analisis keputusan, decision tree  dan diagram yang terkait dengan itu digunakan sebagai alat pendukung  keputusan visual dan analitis, dimana akan dihitungnya nilai atau  utilitas yang diharapkan dari alternatif yang ada.</p>
<ul>
<li>
<p><strong>Decision tree terdiri dari tiga jenis simpul:</strong></p>
</li>
<li>
<p>Simpul keputusan - biasanya diwakili oleh kotak</p>
</li>
<li>Simpul peluang - biasanya diwakili oleh lingkaran</li>
<li>Simpul akhir - biasanya diwakili oleh segitiga</li>
</ul>
<p>Decision tree biasanya digunakan dalam  riset operasi dan manajemen operasi. Jika, dalam praktiknya, keputusan  harus diambil secara online tanpa penarikan kembali di bawah pengetahuan  yang tidak lengkap, sebagai model pilihan terbaik atau algoritma model  seleksi online decision tree harus diparalelkan dengan model  probabilitas. Penggunaan lain dari decision ini yaitu sebagai alat  deskriptif untuk menghitung probabilitas bersyarat.</p>
<p>Dimulai dari kiri ke kanan, decision  tree hanya memiliki simpul burst (jalur pemisahan) dan tidak ada simpul  sink (jalur konvergen). Oleh karena itu, jika digunakan secara manual,  decision tree dapat berkembang jadi sangat besar dan sulit untuk  menggambar semuanya dengan tangan.</p>
<p>Decision Tree dapat dilinearisasi  menjadi aturan keputusan, dimana hasilnya adalah isi dari simpul daun,  dan kondisi di sepanjang jalur membentuk konjungsi dalam klausa if.  Secara umum, bentuk aturannya seperti:</p>
<p>Jika kondisi1 dan kondisi2 dan kondisi3, maka hasil.</p>
<p>Aturan keputusan dapat dihasilkan dengan membuat aturan asosiasi dengan variabel target di sebelah kanan.</p>
<p>Decision tree juga dapat dilihat sebagai  model generatif aturan induksi dari data empiris. Decision tree optimal  kemudian didefinisikan sebagai pohon yang menyumbang sebagian besar  data, sambil meminimalkan jumlah level atau "pertanyaan". Beberapa  algoritma untuk menghasilkan pohon optimal tersebut telah dirancang,  seperti ID3 / &#8536;, CLS, ASSISTANT, dan CART.</p>
<p>Di antara alat pendukung keputusan lainnya, decision tree memiliki beberapa keunggulan, yaitu:</p>
<ul>
<li>Mudah dimengerti dan dipahami. Orang-orang bisa memahami model decision tree dengan penjelasan singkat.</li>
<li>Memiliki nilai walaupun dengan sedikit data yang rumit. Wawasan  penting dapat dihasilkan berdasarkan para ahli yang menggambarkan  situasi dan preferensi mereka untuk hasil.</li>
<li>Membantu menentukan nilai terburuk, terbaik, dan nilai yang diharapkan untuk berbagai skenario.</li>
<li>Menggunakan model kotak putih jika hasil diberikan oleh model.</li>
<li>Dapat dikombinasikan dengan teknik pengambilan keputusan lainnya.</li>
</ul>
<p><strong>Decision tree juga memiliki kekurangan, seperti:</strong></p>
<ul>
<li>Tidak stabil, yang berarti bahwa  perubahan kecil dalam data dapat menyebabkan perubahan besar dalam  struktur decision tree optimal.</li>
<li>Relatif tidak akurat. Banyak prediktor  lain memiliki kinerja yang lebih baik dengan data serupa. Hal ini dapat  diatasi dengan mengganti decision tree tunggal dengan forest of decision  tree acak. Namun hutan yang acak tidak semudah memahami decision tree  tunggal.</li>
<li>Untuk data yang termasuk variabel  kategorikal dengan jumlah level yang berbeda, perolehan informasi dalam  decision tree cenderung mendukung atribut dengan level yang lebih  banyak.</li>
<li>Perhitungan bisa menjadi sangat kompleks, terutama jika banyak nilai tidak pasti dan / atau jika banyak hasil dikaitkan.</li>
</ul>
<h2 id="kelebihan-dan-kekurangan-decision-tree"><strong>Kelebihan dan Kekurangan Decision Tree</strong><a class="headerlink" href="#kelebihan-dan-kekurangan-decision-tree" title="Permanent link">&para;</a></h2>
<h3 id="kelebihan">Kelebihan:<a class="headerlink" href="#kelebihan" title="Permanent link">&para;</a></h3>
<ol>
<li>Mudah dimengerti dan dipahami. Orang-orang bisa memahami model decision tree dengan penjelasan singkat.</li>
<li>Memiliki nilai walaupun dengan sedikit data yang rumit. Wawasan  penting dapat dihasilkan berdasarkan para ahli yang menggambarkan  situasi dan preferensi mereka untuk hasil.</li>
<li>Membantu menentukan nilai terburuk, terbaik, dan nilai yang diharapkan untuk berbagai skenario.</li>
<li>Menggunakan model kotak putih jika hasil diberikan oleh model.</li>
<li>Dapat dikombinasikan dengan teknik pengambilan keputusan lainnya.</li>
</ol>
<h3 id="kekurangan">Kekurangan:<a class="headerlink" href="#kekurangan" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p>Tidak stabil, yang berarti bahwa  perubahan kecil dalam data dapat menyebabkan perubahan besar dalam  struktur decision tree optimal.</p>
</li>
<li>
<p>Relatif tidak akurat. Banyak prediktor  lain memiliki kinerja yang lebih baik dengan data serupa. Hal ini dapat  diatasi dengan mengganti decision tree tunggal dengan forest of decision  tree acak. Namun hutan yang acak tidak semudah memahami decision tree  tunggal.</p>
</li>
<li>
<p>Untuk data yang termasuk variabel  kategorikal dengan jumlah level yang berbeda, perolehan informasi dalam  decision tree cenderung mendukung atribut dengan level yang lebih  banyak.</p>
</li>
<li>
<p>Perhitungan bisa menjadi sangat kompleks, terutama jika banyak nilai tidak pasti dan / atau jika banyak hasil dikaitkan.</p>
</li>
</ol>
<h3 id="algoritma-decision-tree-classification"><strong>Algoritma Decision Tree Classification</strong><a href="https://yusrilx02.github.io/170441100056_Moh_Yusril_Ihza_Maulan/dtc/#algoritma-decision-tree-classification">¶</a><a class="headerlink" href="#algoritma-decision-tree-classification" title="Permanent link">&para;</a></h3>
<ol>
<li>ID3</li>
<li>Gini Index</li>
<li>Chi-Square</li>
<li>Reduction in Variance</li>
</ol>
<p>Namun disini kita hanya membahas ID3 dan Gini index saja.</p>
<p>Untuk  mendapatkan  nilai Information  Gain  dan Gain  Ratio, terlebih  dahulu kita  harus  menghitung nilai entropy.  Eentropy digunakan  untuk  mengukur  nilai  ketidak  murnian  sekumpulan  objek  pada setiap cabang pada suatu atribut. Mila(2015) menyatakan rumus Entropy terdapat pada persamaan :</p>
<p><img alt="img" src="assets/images/Making-intelligent-decisions-with-Decision-Trees-1.png" /></p>
<p>Algoritma ID3 menggunakan entropi untuk menghitung homogenitas sampel. Jika sampel benar-benar homogen, entropinya nol dan jika sampel dibagi sama rata, maka entropinya satu.</p>
<p>Kami akan menggunakan implementasi yang disediakan oleh kerangka pembelajaran mesin python yang dikenal sebagai scikit-belajar untuk memahami Pohon Keputusan.</p>
<p><a href="archive.ics.uci.edu/ml/machine-learning-databases/car/car.data">download data</a></p>
<h2 id="implementasi-dalam-python">Implementasi dalam Python<a class="headerlink" href="#implementasi-dalam-python" title="Permanent link">&para;</a></h2>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span><span class="p">,</span> <span class="n">metrics</span>
</pre></div>

<div class="codehilite"><pre><span></span><span class="c1">#### Langkah pertama</span>
<span class="c1"># Impor data </span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/car_quality/car.data&#39;</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">,</span><span class="s1">&#39;maint&#39;</span><span class="p">,</span><span class="s1">&#39;doors&#39;</span><span class="p">,</span><span class="s1">&#39;persons&#39;</span><span class="p">,</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">,</span><span class="s1">&#39;safety&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span> 
</pre></div>

<h4 id="identifikasi-target-variabel">Identifikasi target variabel<a class="headerlink" href="#identifikasi-target-variabel" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">],</span><span class="n">class_names</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</pre></div>

<h4 id="identifikasi-variabel-prediktor-dan-encode-variabel-string-apa-pun-ke-kode-integer-yang-setara">Identifikasi variabel prediktor dan encode variabel string apa pun ke kode integer yang setara<a class="headerlink" href="#identifikasi-variabel-prediktor-dan-encode-variabel-string-apa-pun-ke-kode-integer-yang-setara" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">],</span><span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;maint&#39;</span><span class="p">],</span><span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;maint&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;doors&#39;</span><span class="p">],</span><span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;doors&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;persons&#39;</span><span class="p">],</span><span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;persons&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">],</span><span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="p">[</span><span class="s1">&#39;safety&#39;</span><span class="p">],</span><span class="n">_</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">factorize</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;safety&#39;</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

<h4 id="pilih-fitur-prediktsi-dan-variabel-target"><strong>Pilih fitur prediktsi dan variabel target</strong><a class="headerlink" href="#pilih-fitur-prediktsi-dan-variabel-target" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

<h4 id="train-test-split">Train test split:<a class="headerlink" href="#train-test-split" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

<h4 id="trainingmodel-fitting"><strong>Training/model fitting</strong><a class="headerlink" href="#trainingmodel-fitting" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span>dtree = tree.DecisionTreeClassifier(criterion=&#39;entropy&#39;, max_depth=3, random_state=0)
dtree.fit(X_train, y_train)
</pre></div>

<h4 id="studi-parameter-model"><strong>Studi parameter model:</strong><a class="headerlink" href="#studi-parameter-model" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span># use the model to make predictions with the test data
y_pred = dtree.predict(X_test)
# how did our model perform?
count_misclassified = (y_test != y_pred).sum()
print(&#39;Misclassified samples: {}&#39;.format(count_misclassified))
accuracy = metrics.accuracy_score(y_test, y_pred)
print(&#39;Accuracy: {:.2f}&#39;.format(accuracy))
</pre></div>

<h4 id="visualization-of-the-decision-graph">Visualization of the decision graph:<a class="headerlink" href="#visualization-of-the-decision-graph" title="Permanent link">&para;</a></h4>
<div class="codehilite"><pre><span></span>import graphviz
feature_names = X.columns

dot_data = tree.export_graphviz(dtree, out_file=None, filled=True, rounded=True,
                                feature_names=feature_names,  
                                class_names=class_names)
graph = graphviz.Source(dot_data)  
graph
</pre></div>

<h3 id="refrensi">Refrensi<a class="headerlink" href="#refrensi" title="Permanent link">&para;</a></h3>
<p><a href="https://garudacyber.co.id/artikel/1545-pengertian-dan-penerapan-decision-tree">https://garudacyber.co.id/artikel/1545-pengertian-dan-penerapan-decision-tree</a></p>
<p><a href="https://acadgild.com/blog/decision-tree-python-code">https://acadgild.com/blog/decision-tree-python-code</a></p></article></div></div></main><footer class="md-footer"><div class="md-footer-meta md-typeset"><div class="md-footer-meta__inner md-grid"><div class="md-footer-copyright"><div class="md-footer-copyright__highlight">Copyright &copy; 2016 - 2019 Martin Donath</div>powered by <a href="https://www.mkdocs.org">MkDocs</a> and <a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a></div></div></div></footer></div><script src="assets/javascripts/application.d5a09f94.js"></script><script>app.initialize({version:"1.0.4",url:{base:"."}})</script></body></html>